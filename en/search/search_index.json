{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Overview","text":"<p>The Sensitive Data Protection on AWS solution allows enterprise customers to create data catalogs, discover, protect, and visualize sensitive data across multiple AWS accounts. The solution eliminates the need for manual tagging to track sensitive data such as Personal Identifiable Information (PII) and classified information. </p> <p>The solution provides an automated approach to data protection with a self-service web application. You can perform regular or on-demand sensitive data discovery jobs using your own data classification templates. Moreover, you can access metrics such as the total number of sensitive data entries stored in all your AWS accounts, which accounts contain the most sensitive data, and the data source\u00a0where the sensitive data is located. </p> <p></p> <p>The solution helps enterprise customers (such as companies with security or big data businesses) to implement the following data protection measures: </p> <ul> <li>centralized management over hundreds of AWS accounts</li> <li>automatic discovery of data assets</li> <li>sensitive data detection and automatic labeling</li> <li>integration with other AWS services or application</li> </ul> <p>This guide provides an overview of the solution, its reference architecture and components, considerations for planning the deployment, configuration steps for deploying the solution to the Amazon Web Services (AWS) Cloud. </p> <p>Use this navigation table to quickly find answers to these questions:</p> If you want to \u2026 Read\u2026 Know the cost for running this solution Cost Understand the security considerations for this solution Security Know which AWS Regions are supported for this solution Supported AWS Regions View or download the AWS CloudFormation template included in this solution to automatically deploy the infrastructure resources (the \u201cstack\u201d) for this solution AWS CloudFormation templates <p>The guide is intended for IT architects, developers, DevOps, data engineers with practical experience architecting on the AWS Cloud.</p>"},{"location":"about-premium-edition/","title":"About Premium Edition","text":""},{"location":"about-premium-edition/#about-sdp-premium-edition-aka-data-customs","title":"About SDP Premium Edition (a.k.a Data Customs)","text":"<p>Sensitive Data Protection Premium Edition (SDP-PE) is a solution offered by AWS Professional Services (the Greater China Regions). It includes not only the features of SDP (this open-source project), but also features for cross-border data transfer (CBDT) scenarios.</p> <p>The features of SDP-PE include, but are not limited to, the following:</p>"},{"location":"about-premium-edition/#cross-border-transfer","title":"Cross-border transfer:","text":"<ul> <li>Cross-border data transfer API </li> <li>Cross-border data transfer approval workflow </li> </ul>"},{"location":"about-premium-edition/#data-inspection","title":"Data inspection:","text":"<ul> <li>Industry-specific classification templates (e.g. for automobile industry)</li> <li>Document inspection (PDF, TXT, etc.)</li> <li>Image inspection (face recognition, OCR, car license, etc.)</li> </ul>"},{"location":"about-premium-edition/#data-masking","title":"Data masking:","text":"<ul> <li>Data masking rule configuration</li> <li>Data masking</li> <li>Image masking (face recognition, OCR, car license, etc.)</li> <li>Document data masking (PDF, TXT, etc.)</li> </ul>"},{"location":"about-premium-edition/#auditing-and-reporting","title":"Auditing and reporting:","text":"<ul> <li>Auditing all API calls (cross-border data transfer, data inspection, data masking) through the solution </li> <li>Viewing dashboard and downloading reports for all records of API calls</li> </ul> <p>For more details, please contact AWS Sales (the Greater China Regions) for further information and a price quote.</p>"},{"location":"contributors/","title":"Contributors","text":"<ul> <li>Chen, Haiyun</li> <li>Cui, Hubin</li> <li>Gu, George</li> <li>Hao, Liang</li> <li>Han, Xu</li> <li>Ji, Junxiang</li> <li>Jia, Ting</li> <li>Li, Xiujuan</li> <li>Lv, Ning</li> <li>Qin, Dehua</li> <li>Su, Fan</li> <li>Wang, Yu</li> <li>Yi, Ke </li> <li>Yi, Yan</li> <li>Zhang, Junzhong</li> </ul>"},{"location":"notices/","title":"Notices","text":"<p>Customers are responsible for making their own independent assessment of the information in this document. This document: (a) is for informational purposes only, (b) represents Amazon Web Services current product offerings and practices, which are subject to change without notice, and (c) does not create any commitments or assurances from Amazon Web Services and its affiliates, suppliers or licensors. Amazon Web Services products or services are provided \u201cas is\u201d without warranties, representations, or conditions of any kind, whether express or implied. Amazon Web Services responsibilities and liabilities to its customers are controlled by Amazon Web Services agreements, and this document is not part of, nor does it modify, any agreement between Amazon Web Services and its customers.</p> <p>The Sensitive Data Protection on AWS solution is licensed under the terms of the Apache License Version 2.0 available at The Apache Software Foundation.</p>"},{"location":"revisions/","title":"Revisions","text":"Date Change June 2023 Initial release"},{"location":"uninstall/","title":"Uninstall the solution","text":"<p>To uninstall the solution, you must delete the AWS CloudFormation stack. </p> <p>You can use either the AWS Management Console or the AWS Command Line Interface (AWS CLI) to delete the CloudFormation stack.</p> <p>Time to uninstall: Approximately 60 minutes</p>"},{"location":"uninstall/#uninstall-the-stack-using-the-aws-management-console","title":"Uninstall the stack using the AWS Management Console","text":"<ol> <li>Sign in to the AWS CloudFormation console.</li> <li>Select this solution\u2019s installation parent stack.</li> <li>Choose Delete.</li> </ol>"},{"location":"uninstall/#uninstall-the-stack-using-aws-command-line-interface","title":"Uninstall the stack using AWS Command Line Interface","text":"<p>Determine whether the AWS Command Line Interface (AWS CLI) is available in your environment. For installation instructions, refer to What Is the AWS Command Line Interface in the AWS CLI User Guide. After confirming that the AWS CLI is available, run the following command.</p> <pre><code>aws cloudformation delete-stack --stack-name &lt;installation-stack-name&gt; --region &lt;aws-region&gt;\n</code></pre>"},{"location":"architecture-details/architecture-details/","title":"How the solution works","text":"<p>his section describes the components and AWS services that make up this solution and the high level system design.</p> <p> Sensitive Data Protection on AWS high level system design</p> <p>As shown in the diagram, the centralized sensitive data governance account is the admin account. Solution users, typically security auditors, can access the solution via a web portal after deploying the Admin stack. Users can browse the data catalog and execute sensitive data detection jobs in the monitored account(s) after deploying the Agent stack and logging into the web portal. </p> <p>Multiple monitored accounts are connected to the admin account with data source access and job execution privileges, so that the admin account can invoke the Job Processor model in the specified monitored account for sensitive data detection.</p>"},{"location":"architecture-details/architecture-details/#modules-in-admin-account","title":"Modules in Admin Account","text":"<ul> <li> <p>Web Portal (UI): The solution administrator or normal users can access the solution through the web portal. It provides secure user access management and a web UI for the solution.</p> </li> <li> <p>Data Source Management (DSM): The DSM is responsible for retrieving the data sources from monitored accounts by the Data Source Detector and storing the data source structure. Users can explore the data storage in the monitored accounts, such as S3 buckets and RDS instances.</p> </li> <li> <p>Data Catalog Management (DCM): The DCM can discover the latest schema (normally called metadata) of the data sources in DSM. The schema includes information such as table columns in RDS databases and the sensitive data detection results after the detection job has run.</p> </li> <li> <p>Job Controller (JC): The Job Controller is responsible for executing the detection job in the monitored account and collecting the detection results back to the admin account. It can configure the job to run on a user-defined schedule or as needed.</p> </li> <li> <p>Template Configuration (TC): The detection templates are stored in the TC model. It contains built-in templates and custom-defined templates. The JC can retrieve the templates for running the job processor.</p> </li> <li> <p>Account Management (AM): The monitored AWS account(s) are managed by the AM model.</p> </li> </ul>"},{"location":"architecture-details/architecture-details/#modules-in-monitored-accounts","title":"Modules in Monitored Account(s)","text":"<ul> <li> <p>Job Processor: The Job Processor is the running container for sensitive data detection, invoked by the Job Controller. The Job Processor reads the raw data to the detection engine for detection and sends the analysis results and running state to the Job Controller.</p> </li> <li> <p>Detection Engine: The Detection Engine model is the core sensitive data detection engine with AI/ML support features. It receives the data from the Job Processor to identify the sensitive data type using a pre-trained ML model or pattern.</p> </li> </ul>"},{"location":"architecture-details/services-in-the-solution/","title":"AWS services in this solution","text":"<p>The following AWS services are included in this solution:</p> AWS service Description Application Load Balancer Core. To distribute the frontend web UI assets. Amazon ECR Core. To store Docker images. AWS Lambda Core. To serve as a target for the application load balancer. AWS Step Functions Supporting.\u00a0To be invoked for sensitive data detection. AWS Glue Supporting.\u00a0To take inventory of data sources. Amazon RDS Supporting. To set up, operate, and scale a relational database in the cloud with just a few clicks. Amazon SQS Supporting.\u00a0To allow the Step Functions to send messages to the detection job queue."},{"location":"architecture-overview/architecture/","title":"Architecture diagram","text":"<p>Deploying this solution with the default parameters builds the following environment in the AWS Cloud.</p> <p> Sensitive Data Protection on AWS architecture</p> <ol> <li>The Application Load Balancer distributes the solution's frontend web UI assets hosted in AWS Lambda. </li> <li>Identity provider for user authentication. </li> <li>The AWS Lambda function is packaged as Docker images and stored in the Amazon ECR (Elastic Container Registry). </li> <li>The backend Lambda function is a target for the Application Load Balancer. </li> <li>The backend Lambda function invokes AWS Step Functions in monitored accounts for sensitive data detection. </li> <li>In AWS Step Functions workflow, the AWS Glue Crawler runs to take inventory of the data sources and is stored in the Glue Database as metadata tables.</li> <li>The Step Functions send Amazon SQS messages to the detection job queue after the Glue job has run. </li> <li>Lambda function processes messages from Amazon SQS.</li> <li>The Amazon Athena query detection results and save to MySQL instance in Amazon RDS.</li> </ol> <p>The solution uses the AWS Glue service as a core for building data catalog in the monitored account(s) and for invoking the Glue Job to detect sensitive data Personal Identifiable Information (PII). The distributed Glue job runs in each monitored account, and the admin account contains a centralized data catalog of data sources across AWS accounts. This is an implementation of the Data Mesh concept recommended by AWS.</p> <p>To be more specific, the solution introduces an event-driven process and uses AWS IAM roles to trigger and communicate between the admin account and the monitored account(s) for sensitive data discovery jobs. The admin account can start PII detection jobs and retrieve data catalogs. All monitored AWS accounts are permitted to be connected to the admin account, which is able to distinguish and access the monitored accounts.</p>"},{"location":"architecture-overview/well-architected-pillars/","title":"AWS Well-Architected pillars","text":"<p>This solution was designed with best practices from the AWS Well-Architected Framework which helps customers design and operate reliable, secure, efficient, and cost-effective workloads in the cloud.</p> <p>This section describes how the design principles and best practices of the Well-Architected Framework were applied when building this solution.</p>"},{"location":"architecture-overview/well-architected-pillars/#operational-excellence","title":"Operational excellence","text":"<p>This section describes how the principles and best practices of the operational excellence pillar were applied when designing this solution.</p> <p>The Sensitive Data Protection on AWS solution pushes metrics, logs and traces to Amazon CloudWatch at various stages to provide observability into the infrastructure, Elastic load balancer, Lambda functions, Step Function workflow and the rest of the solution components.</p>"},{"location":"architecture-overview/well-architected-pillars/#security","title":"Security","text":"<p>This section describes how the principles and best practices of the security pillar were applied when designing this solution.</p> <ul> <li>Sensitive Data Protection on AWS solution web console users are authenticated and authorized with Amazon Cognito or OpenID Connect.</li> <li>All inter-service communications use AWS IAM roles.</li> <li>All roles used by the solution follows least-privilege access. That is, it only contains minimum permissions required so the service can function properly.</li> </ul>"},{"location":"architecture-overview/well-architected-pillars/#reliability","title":"Reliability","text":"<p>This section describes how the principles and best practices of the reliability pillar were applied when designing this solution.</p> <ul> <li>Using AWS serverless services wherever possible (for example, Lambda, Step Functions, Amazon S3, and Amazon SQS) to ensure high availability and recovery from service failure.</li> <li>Scan result metadata is stored in Amazon RDS with multiple Availability Zones (AZs).</li> </ul>"},{"location":"architecture-overview/well-architected-pillars/#performance-efficiency","title":"Performance efficiency","text":"<p>This section describes how the principles and best practices of the performance efficiency pillar were applied when designing this solution.</p> <ul> <li>The ability to launch this solution in any Region that supports AWS services in this solution such as: Amazon S3, Elastic load balancer.</li> <li>Use Serverless architectures remove the need for you to run and maintain physical servers for traditional compute activities.</li> <li>Automatically testing and deploying this solution daily. Reviewing this solution by solution architects and subject matter experts for areas to experiment and improve.</li> </ul>"},{"location":"architecture-overview/well-architected-pillars/#cost-optimization","title":"Cost optimization","text":"<p>This section describes how the principles and best practices of the cost optimization pillar were applied when designing this solution.</p> <ul> <li>Use Autoscaling Group so that the compute costs are only related to how much data is ingested and processed.</li> <li>Using serverless services such as Amazon S3, Amazon Kinesis Data Streams, Amazon EMR Serverless and Amazon Redshift Serverless so that customers only get charged for what they use.</li> </ul>"},{"location":"architecture-overview/well-architected-pillars/#sustainability","title":"Sustainability","text":"<p>This section describes how the principles and best practices of the sustainability pillar were applied when designing this solution.</p> <ul> <li>The solution\u2018s use of managed services (such as Amazon Glue, Amazon Step Functions, Amazon Lambda) are aimed at reducing carbon footprint compared to the footprint of continually operating on-premises servers.</li> <li>The solution decouples senders and receivers of asynchronous messages by Amazon SQS.</li> </ul>"},{"location":"deployment/deployment/","title":"Deployment","text":"<p>Before you launch the solution, review the architecture, supported regions, and other considerations discussed in this guide. Follow the step-by-step instructions in this section to configure and deploy the solution into your account.</p> <p>Time to deploy: Approximately 30 minutes</p>"},{"location":"deployment/deployment/#deployment-overview","title":"Deployment overview","text":"<p>Use the following steps to deploy this solution on AWS. </p> <ul> <li> <p>Step 1. Create an OpenID Connector (OIDC) application</p> </li> <li> <p>Step 2. Deploy the Admin stack</p> </li> <li> <p>Step 3. Configure the OIDC application</p> </li> <li> <p>Step 4. Deploy the Agent stack</p> </li> <li> <p>Step 5. Launch the solution console</p> </li> </ul>"},{"location":"deployment/deployment/#deployment-steps","title":"Deployment steps","text":""},{"location":"deployment/deployment/#step-1-create-an-oidc-application","title":"Step 1. Create an OIDC application","text":"<p>You can use different kinds of OIDC providers. This section introduces Option 1 to Option 3.</p> <ul> <li> <p>Option 1: Cognito, which uses Amazon Cognito as OIDC provider</p> </li> <li> <p>Option 2: Authing, which is an example of third-party authentication providers</p> </li> <li> <p>Option 3: OKTA, which is an example of third-party authentication providers</p> </li> </ul>"},{"location":"deployment/deployment/#option-1-cognito","title":"Option 1: Cognito","text":"<p>You can leverage the Cognito User Pool as the OIDC provider in supported AWS Regions. </p> <ol> <li> <p>Go to the Amazon Cognito console.</p> </li> <li> <p>Set up the hosted UI with the Amazon Cognito console based on this guide.</p> </li> <li> <p>When creating a user pool, from Step 1 to Step 4, choose the options according to your needs.</p> </li> <li> <p>In Step 5 Integrate your app, for App type, choose Public client. Choose Don't generate a client secret under Client secret. </p> </li> <li> <p>In Advanced app client settings, select OpenID, Email and Profile for OpenID Connect scopes. </p> </li> <li> <p>Confirm that the Hosted UI status is Available, and confirm that the OpenID Connect scopes includes email, openid, and profile. </p> </li> <li> <p>Save the App Client ID, User pool ID and the AWS Region to a file, which will be used later.  </p> </li> </ol> <p>In Step 2. Deploy Admin template, the Client ID is the App Client ID, and Issuer URL is <code>https://cognito-idp.${REGION}.amazonaws.com/${USER_POOL_ID}</code> </p>"},{"location":"deployment/deployment/#option-2-authing","title":"Option 2: Authing","text":"<ol> <li> <p>Go to the Authing console.</p> </li> <li> <p>On the left navigation bar, select Self-built App under Applications.</p> </li> <li> <p>Choose Create.</p> </li> <li> <p>Enter the Application Name, and Subdomain.</p> </li> <li> <p>Save the App ID (that is, Client ID) and Issuer (Issuer URL) to a text file from Endpoint Information, which will be used later. </p> </li> <li> <p>Set the Authorization Configuration in Protocol Configuration tab. </p> </li> <li>On the Access Authorization tab, select the accessible users.</li> </ol>"},{"location":"deployment/deployment/#option-3-okta","title":"Option 3: OKTA","text":"<ol> <li> <p>Go to the OKTA console.</p> </li> <li> <p>Choose Applications, and then choose Create App Integration. </p> </li> <li> <p>Choose OIDC - OpenID Connect, then Single-Page Application, and Next. </p> </li> <li> <p>For Controlled access, choose the options that suit your needs and choose Save. </p> </li> <li>Save the Client ID and Issuer URL to a text file from Endpoint Information, which will be used later. The Issuer URL is in your profile. The full Issuer URL is \u201chttps://dev-xxx.okta.com\u201d.  </li> </ol>"},{"location":"deployment/deployment/#step-2-deploy-admin-stack","title":"Step 2. Deploy Admin stack","text":"<p>Deploy the AWS CloudFormation Admin template into your AWS admin account.</p> <ol> <li> <p>Sign in to the AWS Management Console and use the button below to launch the AWS CloudFormation template.</p> Launch in AWS Console Deploy the Admin template with a new VPC in AWS Regions Deploy the Admin template with an existing VPC in AWS Regions Deploy the Admin template with a new VPC in AWS China Regions Deploy the Admin template with an existing VPC in AWS China Regions <p>Important</p> <p>If you choose deployment with an existing VPC, make sure to meet the following requirements:</p> <ul> <li>At least two public subnets and two private subnets.</li> <li>The existing VPC must have NAT gateway. </li> <li>The two private subnets must have routes pointing to NAT gateway.        </li> </ul> </li> <li> <p>To launch this solution in a different AWS Region, use the Region selector in the console navigation bar.</p> </li> <li>On the Create stack page, verify that the correct template URL is shown in the Amazon S3 URL text box and choose Next.</li> <li>On the Specify stack details page, assign a valid and account level unique name to your solution stack.</li> <li> <p>Under Parameters, review the parameters for the template and modify them as necessary. This solution uses the following default values.</p> Parameter Default Description Issuer URL Specify the secure OpenID Connect URL. Maximum 255 characters. URL must begin with <code>https://</code> Client ID Specify the client ID issued by the identity provider. Maximum 255 characters. Use alphanumeric or ?:_.-/? characters Public Access Yes If you choose No, the portal website can be accessed ONLY in the VPC. If you want to access the portal website over Internet, you need to choose Yes Port 80 If an ACM certificate ARN has been added, we recommend using port 443 as the default port for HTTPS protocol. Otherwise, port 80 can be set as an alternative option ACM Certificate ARN (Optional) To enable secure communication through encryption and enhancing the security of the solution, you can add a public certificate ARN from ACM to create the portal website URL based on the HTTPS protocol Custom Domain Name (Optional) By adding your own domain name, such as sdps.example.com, you can directly access the portal website by adding a CNAME record to that domain name after deploying the stack. You only need to enter the domain name, excluding <code>http(s)://</code> </li> <li> <p>Choose Next.</p> </li> <li>On the Configure stack options page, choose Next.</li> <li>On the Review page, review and confirm the settings. Select 3 checkboxes that I acknowledge.</li> <li>Choose Create stack to deploy the stack. Wait for about 20 minutes to ensure that all related resource are created. You can choose the Resource and Event tab to see the status of the stack.</li> <li>Select the Outputs tab to check the <code>POrtalUrlHTTP(S)</code> and <code>SigninRedirectUriHTTP(S)</code>, which will be used to configure the OIDC aplication in Step 3. Configure the OIDC application. </li> </ol>"},{"location":"deployment/deployment/#step-3-configure-the-oidc-application","title":"Step 3. Configure the OIDC application","text":"<p>Copy the value of <code>SigninRedirectUriHTTP(S)</code> and configure it into your OIDC application.</p>"},{"location":"deployment/deployment/#option-1-cognito_1","title":"Option 1: Cognito","text":"<ol> <li>Go to your user pools.</li> <li>Choose App integration.</li> <li>Choose Your App.</li> <li>Make the following configurations. </li> </ol>"},{"location":"deployment/deployment/#option-2-authing_1","title":"Option 2: Authing","text":""},{"location":"deployment/deployment/#option-3-otka","title":"Option 3: OTKA","text":""},{"location":"deployment/deployment/#step-4-configure-custom-domain-name","title":"Step 4. Configure custom domain name","text":"<p>If you entered a custom domain name when deploying the Admin stack, set the CName of the custom domain name to LoadBalancerDnsNameHTTP(S) value on the Output tab of CloudFormat.</p> <ol> <li>Obtain the LoadBalancerDnsNameHTTP(S) as the endpoint from the Outputs tab. </li> <li>Create a CNAME record in DNS resolver, which points to the endpoint address.</li> </ol>"},{"location":"deployment/deployment/#step-5-launch-the-solution-console","title":"Step 5. Launch the solution console","text":"<ol> <li>Obtain the value of PortalUrlHTTP(S) from the Outputs tab.</li> <li>Launch the solution's console by entering the value in the browser. </li> </ol>"},{"location":"deployment/deployment/#step-6-deploy-the-agent-stack","title":"Step 6. Deploy the Agent stack","text":"<p>Deploy the AWS CloudFormation Agent template into your AWS monitored account.</p> <p>Important</p> <p>You can deploy the Agent stack on one or multiple accounts to be monitored.</p> <ol> <li> <p>Sign in to the AWS Management Console and use the button below to launch the AWS CloudFormation template.</p> Launch in AWS Console Deploy the Agent template in AWS Regions Deploy the Agent template in AWS China Regions </li> <li> <p>To launch this solution in a different AWS Region, use the Region selector in the console navigation bar.</p> </li> <li>On the Create stack page, verify that the correct template URL is shown in the Amazon S3 URL text box and choose Next.</li> <li>On the Specify stack details page, enter a Stack name.</li> <li>In the Admin Account ID field, enter the Account ID (12 digits) of the Admin account. This means that this account will be a monitored account by the specified Admin account.</li> <li>Follow the remaining steps described in Step 2. Deploy the Admin stack to complete deploying the Agent stack.</li> </ol>"},{"location":"deployment/template/","title":"AWS CloudFormation template","text":"<p>To automate deployment, this solution uses the following AWS CloudFormation templates, which you can download before deployment:</p> <p>To use the solution, you need to deploy the Admin template on an admin account and the Agent template on one or multiple monitored accounts. Only the accounts which are deployed with the Agent template can be monitored, which are also called monitored account.</p> <p>If all your accounts are within AWS Organizations, you need to deploy the IT template on an IT account. The AWS organization root user needs to first register the IT account as a delegated administrator.</p>"},{"location":"deployment/template/#aws-global-regions","title":"AWS Global Regions","text":"<ul> <li>Template for Admin account (Admin template) in New VPC</li> <li>Template for Admin account (Admin template) in Existing VPC</li> <li>Template for Monitored account (Agent template)</li> <li>Template for IT account (IT template)</li> </ul>"},{"location":"deployment/template/#aws-china-regions","title":"AWS China Regions","text":"<ul> <li>Template for Admin account (Admin template) in New VPC</li> <li>Template for Admin account (Admin template) in Existing VPC</li> <li>Template for Monitored account (Agent template)</li> <li>Template for IT account (IT template)</li> </ul>"},{"location":"developer-guide/source/","title":"Source code","text":"<p>Visit our GitHub repository to download the templates and scripts for this solution. The Sensitive Data Protection on AWS Solution template is generated using the AWS Cloud Development Kit (CDK). Refer to the README.md file for additional information.</p>"},{"location":"plan-deployment/cost/","title":"Cost","text":"<p>You will be responsible for the cost of the AWS services used when running the solution. The main factors affecting the solution cost include:</p> <ul> <li>the number and size of datasets</li> <li>the number and complexity of data structure</li> <li>the frequency of discovery job updates</li> </ul> <p>For example, running a discovery job on a large dataset with a fully scanned range will result in higher costs than running the job on smaller datasets with increased scan range and limited scan depth that are run on demand.</p> <p>As of June 2023, the cost for main AWS account running this solution with the default settings in the AWS China Ningxia Region operated by NWCD (cn-northwest-1) is approximately 901.82 CNY a month.</p>"},{"location":"plan-deployment/cost/#cost-estimation","title":"Cost estimation","text":"<p>Based on typical usage patterns, the following list a few scenarios to provide an estimation of monthly costs. The AWS services listed are billed on a monthly basis.</p>"},{"location":"plan-deployment/cost/#china-ningxia-region-cost","title":"China Ningxia Region Cost","text":"<ul> <li>Base cost for Infra (in Admin account)</li> </ul> Service Usage type Usage quantity Monthly cost (CNY) Type Amazon Relational Database Service for MySQL Community Edition CNY 0.8 per db.t3.medium Multi-AZ instance hour (or partial hour) running MySQL 720 Hrs 576 Reserved Amazon Relational Database Service Provisioned Storage CNY 1.5308 per GB-month of provisioned gp2 storage for Multi-AZ deployments running MySQL 20 GB-Mo 30.616 On Demand Amazon Elastic Compute Cloud NatGateway CNY 0.37 per GB Data Processed by NAT Gateways 30 GB-Mo 11.1 On Demand. Avg 80 url requests per day 0.37 CNY per NAT Gateway Hour 720 Hrs 266.4 Reserved Athena CNY 34.34 per Terabytes for DataScannedInTB in China (Ningxia) 0.010 Terabytes 0.34 On Demand CloudWatch First 5GB-mo per month of logs storage is free. CNY 0.244 per GB archived per month 0.100 GB-Mo 0.244 On Demand EC2 Container Registry (ECR) 500MB-month Free Tier, CNY 0.69 per GB-month 0.003 GB-Mo 0.69 Reserved Elastic Load Balancing - Application 0.0 CNY per Application LoadBalancer-hour (or partial hour) under monthly free tier. CNY 0.156 per Application load balancer-hour (or partial hour) 10 Hrs 1.56 On Demand 0.0 CNY per used Application load balancer capacity unit-hour (or partial hour) under monthly free tier. CNY 0.072 per LCU-hour (or partial hour) 0.105 LCU-Hrs 0 On Demand Lambda CNY 0 for first 400K GB-second usage of AWS Lambda - Total Compute - China (Ningxia), CNY 0.0000001135 Price per 1ms  (Ningxia) 100,000.000 Lambda-GB-Second 11.35 On Demand CNY 0 for first 1M usage of AWS Lambda - Total Requests - China (Ningxia), CNY 1.36 per million requests 10,000 Request 0 On Demand Simple Queue Service First 1,000,000 Amazon SQS Requests per month are free, CNY 3.33 (per Million requests) 100,000 Requests 3.33 On Demand Simple Storage Service First 2,000 PUTs free under free tier, CNY 0.00405 PUT, COPY, POST, LIST requests (per 1,000 requests) 2,000 Requests 0.0081 On Demand First 20,000 GETs free under free tier, CNY 0.0135 per 10,000 requests 4,000 Requests 0.0054 On Demand First 5 GB free under free tier, CNY 0.1755 per GB 0.032 GB-Mo CNY 0.00 0.1755 On Demand Total 901.819 <ul> <li>Base cost for Infra (in monitored account)</li> </ul> Service Usage Type Glue 3.021 CNY per DPU-Hour, billed per second, with a 10-minute minimum per crawler run On Demand 3.021 CNY per Data Processing Unit-Hour for Amazon Glue ETL job On Demand 6.866 CNY per 1,000,000 requests for Amazon Glue Data Catalog request On Demand Step Functions CNY 0.00 for first 4,000 state transitions, CNY 0.0002102 per state transition thereafter On Demand CloudWatch First 5GB-mo per month of logs storage is free. CNY 0.244 per GB archived per month On Demand <ul> <li>Cost Example</li> </ul> <p>The AWS services listed in the example cost tables below are billed on a monthly basis in a monitored account. Glue Crawler minimum cost is 0.5035 (CNY), the crawler will be launched in data source connection creation and PII detection job execution, below cost table includes both of the connection creation and job execution cost with the example data sources.</p> Scenarios Service Running Cost (CNY) Monthly Cost (CNY) Account 1, scan frequency monthly, scan depth 1000 <li>S3 Bucket A: 10000 CSV files, 1000 rows, 10 columns, total size 1.7GiB</li><li>S3 Bucket B: 10000 JSON files, 1000 rows, 10 fields, total size 2.5GiB</li><li>S3 Bucket C: 1000 PARQUET files, 1000 rows, 10 fields, total size 212Mb</li> <li>Glue Crawler: 1.007</li><li>Glue Job: 2.3161</li> 3.3231 Account 2, scan frequency weekly, scan depth 1000 <li>RDS Aurora MySQL A: 10 tables, 10000 rows, 10 columns, instance type: db.r5.large(8vCPUs, 64GiB RAM Network: 4,750 Mbps)</li><li>RDS MySQL B: 10 tables, 1,000,000 rows, 10 columns, instance type: db.m5.12xlarge(48 vCPU 192 GiB RAM Network:9500 Mbps)</li> <li>Glue Crawler: 2.5175</li><li>Glue Job: 2.8196</li> 5.3371 Account 3, scan frequency daily, scan depth 1000 <li>S3 Bucket A: 10000 CSV files, 1000 rows, 10 columns, total size 1.7GiB</li><li>S3 Bucket B: 10000 JSON files, 1000 rows, 10 fields, total size 2.5GiB</li><li>S3 Bucket C: 1000 PARQUET files, 1000 rows, 10 fields, total size 212Mb</li><li>RDS Aurora MySQL A: 10 tables, 10000 rows, 10 columns, instance type: db.r5.large(8vCPUs, 64GiB RAM Network: 4,750 Mbps)</li> <li>Glue Crawler: 15.6085</li><li>Glue Job: 70.9935</li> 86.602 Total monthly cost in the above three accounts with different frequency (CNY) 95.2622"},{"location":"plan-deployment/cost/#us-east-1-region-cost","title":"US East-1 Region Cost","text":"<ul> <li>Base cost for Infra (in Admin account)</li> </ul> Service Usage Type Usage Quantity Monthly cost (USD) Amazon Relational Database Service for MySQL Community Edition USD 0.136 per db.t3.medium Multi-AZ instance hour (or partial hour) running MySQL 720 Hrs 97.92 Reserved Amazon Relational Database Service Provisioned Storage USD 0.23 per GB-month of provisioned gp2 storage for Multi-AZ deployments running MySQL 20 GB-Mo 4.6 On Demand Amazon Elastic Compute Cloud NatGateway USD 0.045 per GB Data Processed by NAT Gateways 30 GB-Mo 1.35 On Demand. Avg 80 url requests per day USD 0.045 per NAT Gateway Hour 720 Hrs 32.4 Reserved Athena 5.00 USD per Terabytes for DataScannedInTB in US East (N. Virginia) 0.010 Terabytes 0.05 On Demand CloudWatch First 5GB per month of log data ingested is free. USD 0.5 per GB archived per month 0.100 GB-Mo 0.05 On Demand Elastic Load Balancing - Application $0.0 per used Application load balancer capacity unit-hour (or partial hour) under monthly free tier 10 Hrs 0 On Demand $0.00 per Application LoadBalancer-hour (or partial hour) under monthly free tier 0.105 LCU-Hrs 0 On Demand Lambda AWS Lambda - Compute Free Tier - 400,000 GB-Seconds - US East (Northern Virginia), after free tier $0.0000166667 for every GB-second 5,0000 Lambda-GB-Second 0.08333 On Demand AWS Lambda - Ephemeral Storage - US East (N. Virginia), after free tier $0.0000000309 for every GB-second 10,000 Request 0 On Demand Simple Queue Service First 1,000,000 Amazon SQS Requests per month are free, after free tier $0.40 (per Million requests) 100,000 Requests 0.04 On Demand Simple Storage Service First 2,000 PUTs free under free tier, CNY $0.005 per 1,000 PUT, COPY, POST, or LIST requests 2,000 Requests 0.01 On Demand First 20,000 GETs free under free tier, $0.0004 per 10,000 requests 4,000 Requests 0.0002 On Demand First 5 GB free under free tier, $0.023 per GB 1 GB 0.023 On Demand Total 136.52653 <ul> <li>Base cost for Infra (in monitored account)</li> </ul> Service Usage Type Glue $0.44 per DPU-Hour, billed per second, with a 10-minute minimum per crawler run On Demand $0.44 per Data Processing Unit-Hour for Amazon Glue ETL job On Demand $1 per 1,000,000 requests for Amazon Glue Data Catalog request On Demand Step Functions US 0.00 for first 4,000 state transitions, $0.025 per 1,000 state transitions On Demand CloudWatch First 5GB per month of log data ingested is free. USD 0.5 per GB archived per month On Demand <p>The basic cost of infrastructure in a monitored account is charged on a pay-as-you-go basis. This means that you only pay for the actual resources that you use, without having to purchase or reserve any capacity in advance. Additionally, AWS provides some free usage tiers to help you understand and evaluate the usage of the service.</p> <p>We recommend using the AWS Cost Explorer feature in the solution to help manage costs. Prices are subject to change. For full details, refer to the pricing webpage for each AWS service used in this solution. </p>"},{"location":"plan-deployment/regions/","title":"Regional Deployment","text":"<p>This solution uses services which may not be currently available in all AWS Regions. Launch this solution in an AWS Region where required services are available. For the most current availability by Region, refer to the AWS Regional Services List.</p>"},{"location":"plan-deployment/regions/#supported-regions-for-deployment-in-aws-global-regions","title":"Supported regions for deployment in AWS Global Regions","text":"Region Name Region ID US East (N. Virginia) Region us-east-1 US East (Ohio) Region us-east-2 US West (N. California) Region us-west-1 US West (Oregon) Region us-west-2 Asia Pacific (Mumbai) Region ap-south-1 Asia Pacific (Tokyo) Region ap-northeast-1 Asia Pacific (Seoul) Region ap-northeast-2 Asia Pacific (Singapore) Region ap-southeast-1 Asia Pacific (Sydney) Region ap-southeast-2 Canada (Central) Region ca-central-1 Europe (Ireland) Region eu-west-1 Europe (London) Region eu-west-2 Europe (Paris) Region eu-west-3 Europe (Frankfurt) Region eu-central-1 South America (Sao Paulo) Region sa-east-1"},{"location":"plan-deployment/regions/#supported-regions-for-deployment-in-aws-china-regions","title":"Supported regions for deployment in AWS China Regions","text":"Region Name Region ID AWS China (Beijing) Region operated by Sinnet cn-north-1 AWS China (Ningxia) Region operated by NWCD cn-northwest-1"},{"location":"plan-deployment/security/","title":"Security Information","text":"<p>When you build systems on AWS infrastructure, security responsibilities are shared between you and AWS. This Shared Responsibility Model reduces your operational burden because AWS operates, manages, and controls the components including the host operating system, the virtualization layer, and the physical security of the facilities in which the services operate. For more information about AWS security, visit AWS Cloud Security.</p>"},{"location":"plan-deployment/security/#iam-roles","title":"IAM roles","text":"<p>AWS Identity and Access Management (IAM) roles allow customers to assign fine-grained access policies and permissions to services and users on AWS. This solution creates IAM roles that grant access between components of the solution.</p>"},{"location":"plan-deployment/security/#monitoring-services-using-amazon-cloudwatch-alarms","title":"Monitoring services using Amazon CloudWatch alarms","text":"<p>You can set up alarms to monitor and receive alerts about your AWS resources on the alarms dashboard in Amazon CloudWatch. Generally, we recommend configuring your alarms to notify you whenever a metric starts excessively over or under-utilizes a particular resource, such as high CPU or memory usage. This can be an indicator that your service is experiencing a DoS-style attack. Additionally, it may be necessary to set alarms when your data storage container, such as RDS, approaches near 100% capacity utilization, because this could indicate a resource starvation or exhaustion-style attack.</p> <p>Warning</p> <p>There could be additional cost for CloudWatch alarms.</p> <p>In AWS China Regions (cn-north-1 and cn-northwest-1), you can create RDS and NAT Gateway metrics in alarms. </p> <p>In AWS Regions, you can enable more services metrics like Lambda, SQS, Application Load Balancer.</p> <p>For example, if you want to create alarms to monitor ActiveConnectionCount in NATGateway using the CloudWatch console, follow the steps below.</p> <ol> <li>Sign in to the AWS Management Console.</li> <li>Access the CloudWatch console.</li> <li>In the navigation pane, choose All alarms under Alarms, and then choose Create alarm.</li> <li>Choose Select metric, and choose NATGateway in metrics.</li> <li>Search for the metric ActiveConnectionCount, click it and select it.</li> <li>Choose Select metric.</li> <li>In Conditions, define the alarm condition whenever ActiveConnectionCount is greater than 100. Then choose Next.</li> <li>In the Notification, configure CloudWatch to send you an email when the alarm state is triggered.</li> <li>Choose Next.</li> <li>Enter a name and description for the alarm and Create alarm.</li> </ol>"},{"location":"solution-overview/concepts-and-definitions/","title":"Concepts and definitions","text":"<ul> <li>Data source: AWS resources where data is stored, such as Amazon S3, and Amazon RDS.</li> <li>Data catalog: A repository of metadata of a data source, allowing you to manage data at the column level. For example, you can view the table schema, sample data of a particular column, and add labels to specific data fields.</li> <li>Data identifier: The rule used to detect data. You can define custom data identifiers using RegEx and keywords.</li> <li>Classification template: A collection of data identifiers. Data identifiers are rules used to detect data.</li> <li>Sensitive data discovery job: A job that uses a template to detect sensitive data. The job automatically labels sensitive data in the data catalog.</li> <li>Glue job: A job that is triggered by a sensitive data discovery job to scan sensitive data using AWS Glue. One discovery job can trigger AWS Glue jobs in multiple AWS accounts in a distributed manner.</li> </ul>"},{"location":"solution-overview/features-and-benefits/","title":"Features and benefits","text":"<p>The solution includes the following features:</p> <p>Data discovery: supports various data sources, such as Amazon S3 and Amazon RDS, across multiple AWS accounts. The solution allows you to easily create a data catalog and run sensitive data discovery jobs. The solution leverages not only pattern-based discovery but also ML classification based on deep learning Natural Language Processing (NLP) and Named Entity Recognition (NER).</p> <p>Flexible data classification: defines data classification templates for detecting privacy data, such as personal information. The solution allows you to define custom sensitive data types or choose from over 200 built-in data types.</p> <p>Centralized data visualization: provides the dashboards with an overview of the data catalogs and sensitive data status, such as data location, and data sources.</p>"},{"location":"user-guide/appendix-built-in-identifiers/","title":"Appendix - Built-in data identifiers","text":"<p>The solution uses machine learning and pattern matching to detect sensitive data. These are 200+ built-in data identifiers for general and country-specific data types. </p> <p>For more information</p> <p>In this solution, some built-in data identifiers, such as person names and addresses, are defined based on AI, while others are defined based on Regex/keywords.</p>"},{"location":"user-guide/appendix-built-in-identifiers/#general-data-identifiers","title":"General data identifiers","text":"Data identifier Description PERSON_NAME Person name (English/Latin specific) EMAIL The email address DATE The date in general format PHONE_NUMBER The phone number (mainly US) BANK_ACCOUNT The bank card (mainly US and Canada specific) CREDIT_CARD The credit card number (mainly US/universal format) IP_ADDRESS The IP address MAC_ADDRESS The Mac address"},{"location":"user-guide/appendix-built-in-identifiers/#country-specific-data-identifiers","title":"Country-specific data identifiers","text":"Country Data identifier Description Argentina ARGENTINA_TAX_IDENTIFICATION_NUMBER Argentina Tax Identification Number, also known as CUIT or CUIL Australia AUSTRALIA_BUSINESS_NUMBER Australia Business Number (ABN). A unique identifier issued by the Australian Business Register (ABR) to identify businesses to the government and community. Australia AUSTRALIA_COMPANY_NUMBER Australia Company Number (ACN). Unique identifier issued by the Australian Securities and Investments Commission. Australia AUSTRALIA_DRIVING_LICENSE The driver license number (Australia specific) Australia AUSTRALIA_MEDICARE_NUMBER Australian Medicare Number. Personal identifier issued by the Australian Health Insurance Commission. Australia AUSTRALIA_PASSPORT_NUMBER The passport number (Australia specific) Australia AUSTRALIA_TAX_FILE_NUMBER Australia Tax File Number (TFN). Issued by the Australian Taxation Office (ATO) to taxpayers (individual, company, etc) for tax dealings. Austria AUSTRIA_DRIVING_LICENSE The driver license number (Austria specific) Austria AUSTRIA_PASSPORT_NUMBER The passport number (Austria specific) Austria AUSTRIA_SSN The social security number (for Austria persons) Austria AUSTRIA_TAX_IDENTIFICATION_NUMBER Tax identification number (Austria specific) Austria AUSTRIA_VALUE_ADDED_TAX Value-Added Tax (Austria specific) Belgium BELGIUM_DRIVING_LICENSE The driver license number (Belgium specific) Belgium BELGIUM_NATIONAL_IDENTIFICATION_NUMBER The Belgian National Number (BNN) Belgium BELGIUM_PASSPORT_NUMBER The passport number (Belgium specific) Belgium BELGIUM_TAX_IDENTIFICATION_NUMBER Tax identification number (Belgium specific) Belgium BELGIUM_VALUE_ADDED_TAX Value-Added Tax (Belgium specific) Bosnia BOSNIA_UNIQUE_MASTER_CITIZEN_NUMBER Unique master citizen number (JMBG) for Bosnia-Herzegovina citizens Brazil BRAZIL_BANK_ACCOUNT The bank account number (Brazil specific) Brazil BRAZIL_NATIONAL_IDENTIFICATION_NUMBER The national identifier (Brazil specific) Brazil BRAZIL_NATIONAL_REGISTRY_OF_LEGAL_ENTITIES_NUMBER The identification number issued to companies (Brazil specific), also known as the CNPJ Brazil BRAZIL_NATURAL_PERSON_REGISTRY_NUMBER The identification number issued to person (Brazil specific) Bulgaria BULGARIA_DRIVING_LICENSE The driver license number (Bulgaria specific) Bulgaria BULGARIA_UNIFORM_CIVIL_NUMBER Unified Civil Number (EGN) that serves as a national identification number Bulgaria BULGARIA_VALUE_ADDED_TAX Value-Added Tax (Bulgaria specific) Canada CANADA_DRIVING_LICENSE The driver license number (Canada specific) Canada CANADA_GOVERNMENT_IDENTIFICATION_CARD_NUMBER The national identifier (Canada specific) Canada CANADA_PASSPORT_NUMBER The passport number (Canada specific) Canada CANADA_PERMANENT_RESIDENCE_NUMBER Permanent residence number (PR Card number) Canada CANADA_PERSONAL_HEALTH_NUMBER The unique identifier for healthcare (PHN number) Canada CANADA_SOCIAL_INSURANCE_NUMBER The social insurance number (SIN) in Canada Chile CHILE_DRIVING_LICENSE The driver license number (Chile specific) Chile CHILE_NATIONAL_IDENTIFICATION_NUMBER The Chile national identifier, also known as RUT or RUN China and territories CHINA_IDENTIFICATION The identification card id (China specific) China and territories CHINA_PHONE_NUMBER The mobile or landland phone number (China specific) China and territories CHINA_PASSPORT_NUMBER The passport number (China specific) China and territories CHINA_LICENSE_PLATE_NUMBER The car license plate number (China specific) China and territories CHINA_MAINLAND_TRAVEL_PERMIT_ID_TAIWAN A China mainland travel permit id number for Taiwan residents China and territories CHINA_MAINLAND_TRAVEL_PERMIT_ID_HONG_KONG_MACAU A China mainland travel permit id number for Hong Kong and Macau residents China and territories HONG_KONG_IDENTITY_CARD The Hong Kong Identification card id China and territories MACAU_RESIDENT_IDENTITY_CARD The Macau Identification card id China and territories TAIWAN_NATIONAL_IDENTIFICATION_NUMBER The Taiwan Identification card id China and territories TAIWAN_PASSPORT_NUMBER The Taiwan passport number China and territories CHINA_CHINESE_NAME AI-based identifier for detecting Chinese name. (Built-in) China and territories CHINA_ADDRESS AI-based identifier for detecting Chinese address. (Built-in) China and territories CHINA_NATIONALITY Regex-based identifier for detecting Chinese nationality (Built-in) China and territories CHINA_BANK_CARD Regex-based identifier for detecting Chinese bank card Id (Built-in) China and territories CHINA_MARITAL_STATUS Regex-based identifier for detecting Marital status (Built-in) China and territories CHINA_POLITICAL_PARTY Regex-based identifier for detecting Chinese Political party (Built-in) China and territories CHINA_PROVINCE Regex-based identifier for detecting China province (Built-in) China and territories CHINA_GENDER Regex-based identifier for detecting Gender (Built-in) China and territories CHINA_ID_TYPE Regex-based identifier for detecting for Id Card type (Built-in) Colombia COLOMBIA_PERSONAL_IDENTIFICATION_NUMBER Unique identifier assigned to Colombians at birth Colombia COLOMBIA_TAX_IDENTIFICATION_NUMBER Tax identification number (Colombia specific) Croatia CROATIA_DRIVING_LICENSE The driver license number (Croatia specific) Croatia CROATIA_IDENTITY_NUMBER The national identifier (Croatia specific) Croatia CROATIA_PASSPORT_NUMBER The passport number (Croatia specific) Croatia CROATIA_PERSONAL_IDENTIFICATION_NUMBER The personal identifier number (OIB) Cyprus CYPRUS_DRIVING_LICENSE The driver license number (Cyprus specific) Cyprus CYPRUS_NATIONAL_IDENTIFICATION_NUMBER The Cypriot identity card Cyprus CYPRUS_PASSPORT_NUMBER The passport number (Cyprus specific) Cyprus CYPRUS_TAX_IDENTIFICATION_NUMBER Tax identification number (Cyprus specific) Cyprus CYPRUS_VALUE_ADDED_TAX Value-Added Tax (Cyprus specific) Czechia CZECHIA_DRIVING_LICENSE The driver license number (Czechia specific) Czechia CZECHIA_PERSONAL_IDENTIFICATION_NUMBER The personal identifier number (Czechia specific) Czechia CZECHIA_VALUE_ADDED_TAX Value-Added Tax (Czechia specific) Denmark DENMARK_DRIVING_LICENSE The driver license number (Denmark specific) Denmark DENMARK_PERSONAL_IDENTIFICATION_NUMBER The personal identifier number (Denmark specific) Denmark DENMARK_TAX_IDENTIFICATION_NUMBER Tax identification number (Denmark specific) Denmark DENMARK_VALUE_ADDED_TAX Value-Added Tax (Denmark specific) Estonia ESTONIA_DRIVING_LICENSE The driver license number (Estonia specific) Estonia ESTONIA_PASSPORT_NUMBER The passport number (Estonia specific) Estonia ESTONIA_PERSONAL_IDENTIFICATION_CODE The personal identifier number (Estonia specific) Estonia ESTONIA_VALUE_ADDED_TAX Value-Added Tax (Estonia specific) Finland FINLAND_DRIVING_LICENSE The driver license number (Finland specific) Finland FINLAND_HEALTH_INSURANCE_NUMBER The health insurance number (Finland specific) Finland FINLAND_NATIONAL_IDENTIFICATION_NUMBER The national identifier number (Finland specific) Finland FINLAND_PASSPORT_NUMBER The passport number (Finland specific) Finland FINLAND_VALUE_ADDED_TAX Value-Added Tax (Finland specific) France FRANCE_BANK_ACCOUNT The bank account number (France specific) France FRANCE_DRIVING_LICENSE The driver license number (France specific) France FRANCE_HEALTH_INSURANCE_NUMBER France health insurance number France FRANCE_INSEE_CODE France social security, SSN, or NIR number France FRANCE_NATIONAL_IDENTIFICATION_NUMBER France national identifier number (CNI) France FRANCE_PASSPORT_NUMBER The passport number (France specific) France FRANCE_TAX_IDENTIFICATION_NUMBER Tax identification number (France specific) France FRANCE_VALUE_ADDED_TAX Value-Added Tax (France specific) Germany GERMANY_BANK_ACCOUNT The bank account number (Germany specific) Germany GERMANY_DRIVING_LICENSE The driver license number (Germany specific) Germany GERMANY_PASSPORT_NUMBER The passport number (Germany specific) Germany GERMANY_PERSONAL_IDENTIFICATION_NUMBER The personal identifier number (Germany specific) Germany GERMANY_TAX_IDENTIFICATION_NUMBER Tax identification number (Germany specific) Germany GERMANY_VALUE_ADDED_TAX Value-Added Tax (Germany specific) Greece GREECE_DRIVING_LICENSE The driver license number (Greece specific) Greece GREECE_PASSPORT_NUMBER The passport number (Greece specific) Greece GREECE_SSN The social security number (for Greece persons) Greece GREECE_TAX_IDENTIFICATION_NUMBER Tax identification number (Greece specific) Greece GREECE_VALUE_ADDED_TAX Value-Added Tax (Greece specific) Hungary HUNGARY_DRIVING_LICENSE The driver license number (Hungary specific) Hungary HUNGARY_PASSPORT_NUMBER The passport number (Hungary specific) Hungary HUNGARY_SSN The social security number (for Hungary persons) Hungary HUNGARY_TAX_IDENTIFICATION_NUMBER Tax identification number (Hungary specific) Hungary HUNGARY_VALUE_ADDED_TAX Value-Added Tax (Hungary specific) Iceland ICELAND_NATIONAL_IDENTIFICATION_NUMBER The national identifier (Iceland specific) Iceland ICELAND_PASSPORT_NUMBER The passport number (Iceland specific) Iceland ICELAND_VALUE_ADDED_TAX Value-Added Tax (Iceland specific) India INDIA_AADHAAR_NUMBER Aadhaar identification number issued by the UIDAI India INDIA_PERMANENT_ACCOUNT_NUMBER India Permanent Account Number (PAN) Indonesia INDONESIA_IDENTITY_CARD_NUMBER The national identifier (Indonesia specific) Ireland IRELAND_DRIVING_LICENSE The driver license number (Ireland specific) Ireland IRELAND_PASSPORT_NUMBER The passport number (Ireland specific) Ireland IRELAND_PERSONAL_PUBLIC_SERVICE_NUMBER Ireland personal public service number (PPS) Ireland IRELAND_TAX_IDENTIFICATION_NUMBER Tax identification number (Ireland specific) Ireland IRELAND_VALUE_ADDED_TAX Value-Added Tax (Ireland specific) Israel ISRAEL_IDENTIFICATION_NUMBER The national identifier (Israel specific) Italy ITALY_BANK_ACCOUNT The bank account number (Italy specific) Italy ITALY_DRIVING_LICENSE The driver license number (Italy specific) Italy ITALY_FISCAL_CODE The identifier number, also known as Italian Codice Fiscale Italy ITALY_PASSPORT_NUMBER The passport number (Italy specific) Italy ITALY_VALUE_ADDED_TAX Value-Added Tax (Italy specific) Japan JAPAN_BANK_ACCOUNT The bank account number (Japan specific) Japan JAPAN_DRIVING_LICENSE The driver license number (Japan specific) Japan JAPAN_MY_NUMBER The identifier number (Japan specific) Japan JAPAN_PASSPORT_NUMBER The passport number (Japan specific) Korea KOREA_PASSPORT_NUMBER The passport number (Korea specific) Korea KOREA_RESIDENCE_REGISTRATION_NUMBER_FOR_CITIZENS Korea residence registrant number for citizens Korea KOREA_RESIDENCE_REGISTRATION_NUMBER_FOR_FOREIGNERS Korea residence registrant number for foreigners Kosovo KOSOVO_UNIQUE_MASTER_CITIZEN_NUMBER The unique citizen number (Kosovo specific) Latvia LATVIA_DRIVING_LICENSE The driver license number (Latvia specific) Latvia LATVIA_PASSPORT_NUMBER The passport number (Latvia specific) Latvia LATVIA_PERSONAL_IDENTIFICATION_NUMBER The personal identifier number (Latvia specific) Latvia LATVIA_VALUE_ADDED_TAX Value-Added Tax (Latvia specific) Liechtenstein LIECHTENSTEIN_NATIONAL_IDENTIFICATION_NUMBER The national identifier (Liechtenstein specific) Liechtenstein LIECHTENSTEIN_PASSPORT_NUMBER The passport number (Liechtenstein specific) Liechtenstein LIECHTENSTEIN_TAX_IDENTIFICATION_NUMBER Tax identification number (Liechtenstein specific) Lithuania LITHUANIA_DRIVING_LICENSE The driver license number (Lithuania specific) Lithuania LITHUANIA_PERSONAL_IDENTIFICATION_NUMBER The personal identifier number (Lithuania specific) Lithuania LITHUANIA_TAX_IDENTIFICATION_NUMBER Tax identification number (Lithuania specific) Lithuania LITHUANIA_VALUE_ADDED_TAX Value-Added Tax (Lithuania specific) Luxembourg LUXEMBOURG_DRIVING_LICENSE The driver license number (Luxembourg specific) Luxembourg LUXEMBOURG_NATIONAL_INDIVIDUAL_NUMBER The national identifier (Luxembourg specific) Luxembourg LUXEMBOURG_PASSPORT_NUMBER The passport number (Luxembourg specific) Luxembourg LUXEMBOURG_TAX_IDENTIFICATION_NUMBER Tax identification number (Luxembourg specific) Luxembourg LUXEMBOURG_VALUE_ADDED_TAX Value-Added Tax (Luxembourg specific) Macedonia MACEDONIA_UNIQUE_MASTER_CITIZEN_NUMBER The unique citizen number (Macedonia specific) Malaysia MALAYSIA_MYKAD_NUMBER The national identifier (Malaysia specific) Malaysia MALAYSIA_PASSPORT_NUMBER The passport number (Malaysia specific) Malta MALTA_DRIVING_LICENSE The driver license number (Malta specific) Malta MALTA_NATIONAL_IDENTIFICATION_NUMBER The national identifier (Malta specific) Malta MALTA_TAX_IDENTIFICATION_NUMBER Tax identification number (Malta specific) Malta MALTA_VALUE_ADDED_TAX Value-Added Tax (Malta specific) Mexico MEXICO_CLABE_NUMBER Mexico CLABE (Clave Bancaria Estandarizada) bank number Mexico MEXICO_DRIVING_LICENSE The driver license number (Mexico specific) Mexico MEXICO_PASSPORT_NUMBER The passport number (Mexico specific) Mexico MEXICO_TAX_IDENTIFICATION_NUMBER Tax identification number (Mexico specific) Mexico MEXICO_UNIQUE_POPULATION_REGISTRY_CODE The Clave \u00danica de Registro de Poblaci\u00f3n (CURP) unique identity code for Mexico Montenegro MONTENEGRO_UNIQUE_MASTER_CITIZEN_NUMBER The unique citizen number (Montenegro specific) Netherlands NETHERLANDS_BANK_ACCOUNT The bank account number (Netherlands specific) Netherlands NETHERLANDS_CITIZEN_SERVICE_NUMBER Netherlands citizen number (BSN, burgerservicenummer) Netherlands NETHERLANDS_DRIVING_LICENSE The driver license number (Netherlands specific) Netherlands NETHERLANDS_PASSPORT_NUMBER The passport number (Netherlands specific) Netherlands NETHERLANDS_TAX_IDENTIFICATION_NUMBER Tax identification number (Netherlands specific) Netherlands NETHERLANDS_VALUE_ADDED_TAX Value-Added Tax (Netherlands specific) New Zealand NEW_ZEALAND_DRIVING_LICENSE The driver license number (New Zealand specific) New Zealand NEW_ZEALAND_NATIONAL_HEALTH_INDEX_NUMBER New Zealand health insurance number New Zealand NEW_ZEALAND_TAX_IDENTIFICATION_NUMBER Tax identification number, also known as inland revenue number Norway NORWAY_BIRTH_NUMBER Norwegian national identity number Norway NORWAY_DRIVING_LICENSE The driver license number (Norway specific) Norway NORWAY_HEALTH_INSURANCE_NUMBER Norway health insurance number Norway NORWAY_NATIONAL_IDENTIFICATION_NUMBER The national identifier number (Norway specific) Norway NORWAY_VALUE_ADDED_TAX Value-Added Tax (Norway specific) Philippines PHILIPPINES_DRIVING_LICENSE The driver license number (Philippines specific) Philippines PHILIPPINES_PASSPORT_NUMBER The passport number (Philippines specific) Poland POLAND_DRIVING_LICENSE The driver license number (Poland specific) Poland POLAND_IDENTIFICATION_NUMBER The Poland identifier Poland POLAND_PASSPORT_NUMBER The passport number (Poland specific) Poland POLAND_REGON_NUMBER The REGON identifier number, also known as the Statistical ID Poland POLAND_SSN The social security number (for Poland persons) Poland POLAND_TAX_IDENTIFICATION_NUMBER Tax identification number (Poland specific) Poland POLAND_VALUE_ADDED_TAX Value-Added Tax (Poland specific) Portugal PORTUGAL_DRIVING_LICENSE The driver license number (Portugal specific) Portugal PORTUGAL_NATIONAL_IDENTIFICATION_NUMBER The national identifier number (Portugal specific) Portugal PORTUGAL_PASSPORT_NUMBER The passport number (Portugal specific) Portugal PORTUGAL_TAX_IDENTIFICATION_NUMBER Tax identification number (Portugal specific) Portugal PORTUGAL_VALUE_ADDED_TAX Value-Added Tax (Portugal specific) Romania ROMANIA_DRIVING_LICENSE The driver license number (Romania specific) Romania ROMANIA_NUMERICAL_PERSONAL_CODE The personal identifier number (Romania specific) Romania ROMANIA_PASSPORT_NUMBER The passport number (Romania specific) Romania ROMANIA_VALUE_ADDED_TAX Value-Added Tax (Romania specific) Serbia SERBIA_UNIQUE_MASTER_CITIZEN_NUMBER The unique citizen number (Serbia specific) Serbia SERBIA_VALUE_ADDED_TAX Value-Added Tax (Serbia specific) Serbia VOJVODINA_UNIQUE_MASTER_CITIZEN_NUMBER The unique citizen number for Vojvodina (Serbia specific) Singapore SINGAPORE_DRIVING_LICENSE The driver license number (Singapore specific) Singapore SINGAPORE_NATIONAL_REGISTRY_IDENTIFICATION_NUMBER The national registration identity card for Singapore Singapore SINGAPORE_PASSPORT_NUMBER The passport number (Singapore specific) Singapore SINGAPORE_UNIQUE_ENTITY_NUMBER The unique entity number (Singapore specific) Slovakia SLOVAKIA_DRIVING_LICENSE The driver license number (Slovakia specific) Slovakia SLOVAKIA_NATIONAL_IDENTIFICATION_NUMBER The national identifier number (Slovakia specific) Slovakia SLOVAKIA_PASSPORT_NUMBER The passport number (Slovakia specific) Slovakia SLOVAKIA_VALUE_ADDED_TAX Value-Added Tax (Slovakia specific) Slovenia SLOVENIA_DRIVING_LICENSE The driver license number (Slovenia specific) Slovenia SLOVENIA_PASSPORT_NUMBER The passport number (Slovenia specific) Slovenia SLOVENIA_TAX_IDENTIFICATION_NUMBER Tax identification number (Slovenia specific) Slovenia SLOVENIA_UNIQUE_MASTER_CITIZEN_NUMBER Unique master citizen number (JMBG) for Slovenia citizens Slovenia SLOVENIA_VALUE_ADDED_TAX Value-Added Tax (Slovenia specific) South Africa SOUTH_AFRICA_PERSONAL_IDENTIFICATION_NUMBER The personal identifier number (South Africa specific) Spain SPAIN_DNI The national identity card (Documento Nacional de Identidad) of Spain Spain SPAIN_DRIVING_LICENSE The driver license number (Spain specific) Spain SPAIN_PASSPORT_NUMBER The passport number (Spain specific) Spain SPAIN_SSN The social security number (for Spain persons) Spain SPAIN_TAX_IDENTIFICATION_NUMBER Tax identification number (Spain specific) Spain SPAIN_VALUE_ADDED_TAX Value-Added Tax (Spain specific) Sri Lanka SRI_LANKA_NATIONAL_IDENTIFICATION_NUMBER The national identifier (Sri Lanka specific) Sweden SWEDEN_DRIVING_LICENSE The driver license number (Sweden specific) Sweden SWEDEN_PASSPORT_NUMBER The passport number (Sweden specific) Sweden SWEDEN_PERSONAL_IDENTIFICATION_NUMBER The national identifier number (Sweden specific) Sweden SWEDEN_TAX_IDENTIFICATION_NUMBER Sweden Tax Identification Number (personnummer) Sweden SWEDEN_VALUE_ADDED_TAX Value-Added Tax (Sweden specific) Switzerland SWITZERLAND_AHV The social security number for Swiss persons (AHV) Switzerland SWITZERLAND_HEALTH_INSURANCE_NUMBER Swiss health insurance number Switzerland SWITZERLAND_PASSPORT_NUMBER The passport number (Switzerland specific) Switzerland SWITZERLAND_VALUE_ADDED_TAX Value-Added Tax (Switzerland specific) Thailand THAILAND_PASSPORT_NUMBER The passport number (Thailand specific) Thailand THAILAND_PERSONAL_IDENTIFICATION_NUMBER The personal identifier number (Thailand specific) Turkey TURKEY_NATIONAL_IDENTIFICATION_NUMBER The national identifier number (Turkey specific) Turkey TURKEY_PASSPORT_NUMBER The passport number (Turkey specific) Turkey TURKEY_VALUE_ADDED_TAX Value-Added Tax (Turkey specific) United Kingdom UK_BANK_ACCOUNT The bank account number (UK specific) United Kingdom UK_BANK_SORT_CODE A sort code is a 6 digit number that identifies bank. (UK specific) United Kingdom UK_DRIVING_LICENSE The driver license number (UK specific) United Kingdom UK_ELECTORAL_ROLL_NUMBER The electroral register roll number United Kingdom UK_NATIONAL_HEALTH_SERVICE_NUMBER The national health service number United Kingdom UK_NATIONAL_INSURANCE_NUMBER The national insurance number (UK specific) United Kingdom UK_PASSPORT_NUMBER The passport number (UK specific) United Kingdom UK_PHONE_NUMBER The phone number (UK specific) United Kingdom UK_UNIQUE_TAXPAYER_REFERENCE_NUMBER The unique tax payer number (UK specific) United Kingdom UK_VALUE_ADDED_TAX Value-Added Tax (UK specific) Ukraine UKRAINE_INDIVIDUAL_IDENTIFICATION_NUMBER The unique identifier (Ukraine specific) Ukraine UKRAINE_PASSPORT_NUMBER_DOMESTIC The domestic passport number (Ukraine specific) Ukraine UKRAINE_PASSPORT_NUMBER_INTERNATIONAL The international passport number (Ukraine specific) United Arab Emirates (UAE) UNITED_ARAB_EMIRATES_PERSONAL_NUMBER The personal identifier number (UAE specific) United States of America (USA) USA_SSN The social security number (USA specific) United States of America (USA) USA_ATIN The Adoption Taxpayer Identification Number (USA specific) United States of America (USA) USA_ITIN The Individual Taxpayer Identification Number (USA specific) United States of America (USA) USA_PTIN The Preparer Tax Identification Number (USA specific) United States of America (USA) USA_PASSPORT_NUMBER The passport number (USA specific) United States of America (USA) USA_DRIVING_LICENSE The driver license card ID (USA specific) United States of America (USA) USA_DEA_NUMBER The DEA number (DEA Registration Number) assigned to a healthcare provider (USA specific) United States of America (USA) USA_HCPCS_CODE The Healthcare Common Procedure Coding System (HCPCS) Codes (USA specific) United States of America (USA) USA_NATIONAL_PROVIDER_IDENTIFIER The NPI is a unique identification number for covered healthcare providers (USA specific) United States of America (USA) USA_NATIONAL_DRUG_CODE The universal product identifier for human drugs in the United States (USA specific) United States of America (USA) USA_HEALTH_INSURANCE_CLAIM_NUMBER The identifier assigned to a health insurance claim submitted by a healthcare provider (USA specific) United States of America (USA) USA_MEDICARE_BENEFICIARY_IDENTIFIER The Medicare beneficiary's identification number (USA specific) United States of America (USA) USA_CPT_CODE The Current Procedural Terminology (USA specific) Venezuela VENEZUELA_DRIVING_LICENSE The driver license number (Venezuela specific) Venezuela VENEZUELA_NATIONAL_IDENTIFICATION_NUMBER The national identifier number (Venezuela specific) Venezuela VENEZUELA_VALUE_ADDED_TAX Value-Added Tax (Venezuela specific)"},{"location":"user-guide/appendix-organization/","title":"Add accounts via AWS Organization","text":"<p>You can use AWS Organizations to manage automated deployment of monitored accounts. In AWS CloudFormation, you can configure StackSet to deploy the Agent stack in the target Organizational Unit (OU). After you have configured the deployment, the Agent stack will be automatically deployed to the specified region of the account under the OU. Finally, you need to deploy the IT stack to the Organizations management account or the corresponding CloudFormation delegated account under Organizations, then, you can add member accounts via Organizations.</p>"},{"location":"user-guide/appendix-organization/#concepts","title":"Concepts","text":"<ol> <li>Deploy Admin CloudFormation stack in the Admin account.</li> <li>Register delegated administrator in StackSets in Organization\u2019s management account. For more information, refer to Register a delegated administrator.</li> <li>Deploy IT CloudFormation Stack.</li> <li>Create a role for the solution Admin API.</li> <li>Create StackSet for Agent CloudFormation Stack.</li> <li>Deploy to Organization/OU(s).</li> <li>Add member account via Organizations.</li> <li>Retrieve deployment stacks and member accounts.</li> </ol>"},{"location":"user-guide/appendix-permissions/","title":"Appendix: Permissions for agent CloudFormation stack","text":"<p>The solution follows the least privilege principle to grant permissions to monitored account(s) when deploying Agent CloudFormation template. The Agent CloudFormation Stack basically set AWS roles and policies setup necessary permissions in target accounts to authorize the SDP solution. </p> <p>The permissions can be described at a high-level:</p> <ul> <li>(Data source) Amazon S3: read only permission for data source scanning.</li> <li>(Data source) Amazon RDS: read only permission for data source scanning. </li> <li>AWS SecretsManager: read only permission. If RDS database is secured with Secrets, the solution will read credentials from Secret Manager.</li> <li>AWS Glue: write permission. Glue data catalog, Glue crawler, Glue job are used. Glue is triggered by Step Functions.</li> <li>AWS StepFunctions: resource created. Step Function is used to orchestrate Glue jobs for data discovery.</li> <li>AWS Lambda: resource created.</li> <li>Amazon CloudWatch: write permission. Lambda logs will be stored in CloudWatch.</li> </ul> <p>For more information</p> <p>You can view specific permission details in Template for Monitored account (Agent template)</p>"},{"location":"user-guide/data-catalog-create/","title":"Connect to data source","text":"<p>After onboarding AWS accounts, you can create data catalogs for the data source.</p> <p>Supported data types</p> <ul> <li>Structured data and Semi-structured data are supported.The solution uses AWS Glue to crawl these data into data catalogs. For specific data format supported by AWS Glue, please refer to Built-in classifiers in AWS Glue.</li> <li>Unstructured data (such as Image and PDF) is not supported.</li> </ul>"},{"location":"user-guide/data-catalog-create/#create-data-catalogs-for-s3-manual","title":"Create data catalogs for S3 (manual)","text":"<ol> <li>On the Connect to data source page, click one account to open its details page.</li> <li>In the Amazon S3 tab, view a list of S3 buckets in the region where the solution is deployed. </li> <li>Select a S3 bucket, and choose Sync to data catalog to create or update data catalog. </li> </ol> <p>After several minutes, you can see Catalog status is <code>ACTIVE</code>, which indicates data catalogs are created for the S3 bucket. </p> <p>You can also choose Sync ALL to data catalog from the Actions list to quickly create data catalogs for all S3 buckets of this AWS account.</p>"},{"location":"user-guide/data-catalog-create/#create-data-catalogs-for-rds-manual","title":"Create data catalogs for RDS (manual)","text":"<p>Prerequisite<p>A RDS instance must at least 1 private subnet and also meet one of the conditions to be successfully connected:</p> <ul> <li>It has VPC NAT Gateway.</li> <li>It has both VPC Endpoints for S3 and Glue Endpoint.</li> </ul> </p> <ol> <li>On the Connect to data source page, click one account to open its details page.</li> <li>Choose the Amazon RDS tab. You can see a list of RDS instances in the region where the solution is deployed. </li> <li> <p>Select a RDS instance, and choose Sync to data catalog to open a pop-up window asking for credentials. There are two options to enter the credentials:</p> <ul> <li>Choose Username/Password and enter the username and password of the RDS instance.</li> <li>Choose Secret Manager and select the Secret of the RDS. It will list all the Secrets in Secret Manager of the same account of the RDS.</li> </ul> </li> <li> <p>Choose Connect. The solution will start testing connection, and it could take several minutes.</p> </li> </ol> <p>Once you see catalog status is <code>Active</code>, it indicates that data catalog is created for the RDS instance. </p>"},{"location":"user-guide/data-catalog-delete/","title":"Delete data catalogs","text":"<p>You can delete data catalogs if you do not need them any more.</p>"},{"location":"user-guide/data-catalog-delete/#delete-data-catalogs-for-s3","title":"Delete data catalogs for S3","text":"<ol> <li>On the Connect to data source page, click one account to open its details page.</li> <li>In the S3 tab, select an S3 bucket, and choose Delete data catalog from the Actions list.</li> </ol>"},{"location":"user-guide/data-catalog-delete/#delete-data-catalogs-for-rds","title":"Delete data catalogs for RDS","text":"<ol> <li>On the Connect to data source page, click one account to open its details page.</li> <li>Choose the Amazon RDS tab.</li> <li>Select a RDS instance, and choose Delete data catalog from the Actions list.</li> </ol>"},{"location":"user-guide/data-catalog-labels/","title":"Label data catalog","text":"<p>Data catalog provides metadata for your data source. You can add/update labels for it to give more information of the metadata.</p>"},{"location":"user-guide/data-catalog-labels/#sensitive-data-labeling-automatic-or-manual","title":"Sensitive data labeling (automatic or manual)","text":"<p>After sensitive data job is completed, the \"Privacy field\" will be automatically tagged based on job result. Column-level data in data catalogs will be labeled with data identifiers.</p> <p>You can always manually update the Privacy field in data catalog. </p> <p>In the Browse data catalogs page: </p> <ul> <li>In the S3 tab, either on Bucket or Folder level, you can click the  to select Privacy label.</li> <li>In the RDS tab, either on Instance or Table level, you can click the  to select Privacy label.</li> </ul>"},{"location":"user-guide/data-catalog-labels/#custom-labeling-manual","title":"Custom labeling (manual)","text":"<p>You can use \"Custom label\" field in data catalog to add business related label (for example, line of business, department, team, etc). </p> <p>In the Browse data catalogs page: </p> <ul> <li>In S3 tab, either on Bucket or Folder level, you can click the  to select Custom label from dropdown list.</li> <li>In RDS tab, either on Instance or Table level, you can click the  to select Custom label from dropdown list. </li> </ul> <p>At the bottom of dropdown list, click Manage custom label link, and there will be a pop-up window, in which you can Add/Edit/Delete a custom label. </p>"},{"location":"user-guide/data-catalog-sync/","title":"Synchronize data catalogs","text":""},{"location":"user-guide/data-catalog-sync/#what-is-data-catalog","title":"What is data catalog?","text":"<p>A data catalog is a repository of metadata of data source (Amazon S3, Amazon RDS). With data catalogs, you can view the column-level information of data. </p>"},{"location":"user-guide/data-catalog-sync/#when-are-the-data-catalogs-synchronized-with-data-source","title":"When are the data catalogs synchronized with data source?","text":"<p>The solution synchronizes the data catalogs with data source in the following situations: - Sync to data catalog (manual). Please refer to Connect to data source - Run sensitive data discovery job (automatic)</p> <p>For more information</p> <p>Synchronizing data catalog will not affect the labels on an existing data catalog.</p> AWS resource Data source change Sync to data catalog Run sensitive data discovery jobs S3 bucket created Y Y S3 bucket deleted Y Y S3 object created Y Y S3 object deleted Y Y S3 object(in bucket root) created Y Y S3 object(in bucket root) deleted N N S3 object updated (timestamp changed) Y Y RDS instance created Y Y RDS instance deleted Y Y RDS instance updated Y Y RDS database created Y Y RDS database deleted Y Y RDS table created Y Y RDS table deleted Y Y RDS table updated Y Y RDS column created Y Y RDS column deleted Y Y RDS column updated Y Y"},{"location":"user-guide/data-classification-template/","title":"Data classification template","text":"<p>A template is a collection of data identifiers. You can define sensitive data in the template by adding data identifiers. The template will be used in sensitive data discovery job. </p>"},{"location":"user-guide/data-classification-template/#add-data-identifier-to-template","title":"Add data identifier to template","text":"<ol> <li>Sign in to the solution's web portal.</li> <li>Choose Define classification template in the Summary area. Alternatively, from the left navigation pane, choose Define classification template under Classification settings to open the Define classification template page.</li> <li>Choose Add data identifier. You will see a list of data identifiers in window. </li> <li>Select one or multiple data identifiers and choose Add to template. </li> </ol>"},{"location":"user-guide/data-classification-template/#remove-data-identifier-from-template","title":"Remove data identifier from template","text":"<p>On the Define classification template page, select a data identifier in the template and choose Remove. </p>"},{"location":"user-guide/data-classification-template/#enabledisable-data-identifier","title":"Enable/disable data identifier","text":"<p>On the Define classification template page, for each identifier in the template, you can choose to enable or disable it. If you disable a data identifier, the related job will not detect data against the identifier. Disabling an identifier is usually for testing purposes.</p>"},{"location":"user-guide/data-identifiers/","title":"Manage data identifiers","text":"<p>Data identifiers are rules for detecting sensitive data. First, you need to understand what type of data is defined as sensitive in your company, and the identification rules for this sensitive data. Only sensitive data that can be defined using regular expressions or AI can be identified through technical means (such as through this SDP solution).</p> <p>Once you have defined these data rules (data identifiers), you also need to add them to the data classification template. The sensitive data scanning task will match the data in the data source with the rules in the template one by one, and then label the data catalogs with data identifiers.</p>"},{"location":"user-guide/data-identifiers/#built-in-data-identifiers","title":"Built-in data identifiers","text":"<p>The solution provides built-in data identifiers, which are primarily based on privacy data rules classified by country. In the Manage data identifier page, in the Built-in data identifiers tab, you can see a list of built-in data identifiers. For a full list, please see Appendix - Built-in data identifiers.</p> <p>You can you can click the  to create/edit the properties Category and Identifier label for these data identifiers. By default, these data identifiers has Category property as <code>PERSONAL</code> and Identifier label property as <code>S2</code>/<code>S3</code>/<code>S4</code>. You can update these properties based on your own definition for sensitive data. </p>"},{"location":"user-guide/data-identifiers/#custom-data-identifiers","title":"Custom Data Identifiers","text":"<p>On the Manage Data Identifier page, under the Custom Data Identifiers tab, you can see a list of custom data identifiers that you have defined. The list is empty by default. You can create or remove a data identifier based on your definition of sensitive business data.</p> <p>You can you can click the  to edit the properties Category and Identifier label for these data identifiers based on your own definition for sensitive data. For example, you can define category as <code>FINANCE</code>/<code>AUTO</code>/<code>GENERAL</code> and define data sensitivity level as <code>Level1</code>/<code>Level2</code>/<code>Level3</code>/<code>Level4</code>.</p>"},{"location":"user-guide/data-identifiers/#create-and-edit","title":"Create and edit","text":"<p>To create a new data identifier, select Create Data Identifier or to edit a identifier, click into the identifier name.  You will be redirected to the Data identifier detail page. </p> <ul> <li>When defining identification rules, if you enable both the Regex rule and Keywords rule, a data field must meet both the Regex pattern and match (fully or partially) one of the keywords to be labeled.</li> <li>You can create/edit the properties Category and Identifier label in this page.</li> </ul>"},{"location":"user-guide/data-identifiers/#example-how-data-identifiers-are-labeled-in-data-catalog-after-sensitive-data-discovery-job","title":"Example: how data identifiers are labeled in data catalog after sensitive data discovery job.","text":"<p>Assume we want to detect sensitive data in this table named \"PizzaOrderTable\"</p> id user_name email_address order_id 1 aaa_frankzhu frankzhu@mail.com 12344536 2 aaa_zheng zhm@mail.com 12344536 3 aaa_patrickpark ppark@example.com 12344536 4 aaa_kyle kyle@qq.com 1230000 <p>For example, we define 5 custom data identifiers:</p> Identifier Name Regex Keyword OrderInfo1 OrderInfo1 order OrderInfo2 (disabled) _id UserEmail <code>^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$</code> (disabled) EmailAddress (disabled) themail, email-address, email_address UserPrefix aaa_ user <p>Assume all the above identifiers were added in classification template, and then we started a discovery job. \"PizzaOrderTable\" data catalog result is as below:</p> Column Identifiers Privacy id N/A Non-PII user_name UserPrefix Contain-PII email_address UserEmail, EmailAddress Contain-PII order_id OrderInfo2 Contain-PII <p>Explanation for Identifiers:</p> <ul> <li>The identifier \"OrderInfo1\" is not matched because the regex does not match the data pattern.</li> <li>The identifier \"OrderInfo2\" is labeled on the \"order_id\" column because the keyword \"_id\" partially matches the column name \"order_id\".</li> <li>The identifier \"UserEmail\" is labeled on the \"email_address\" column because the regex matches the data pattern of the \"email_address\" column values.</li> <li>The identifier \"EmailAddress\" is labeled on the \"email_address\" column because one of the keywords \"email_address\" matches the column name.</li> <li>The identifier \"UserPrefix\" is labeled on the \"user_name\" column because both the regex and keywords match.</li> </ul> <p>Explanation for Privacy labels:</p> <ul> <li>Columns \"user_name\", \"email_address\", and \"order_id\" are labeled as (Contain-PII) privacy label because identifiers are matched.</li> <li>Column \"id\" is labeled as (Non-PII) privacy label because no identifier is matched.</li> </ul>"},{"location":"user-guide/data-source/","title":"Connect to data source","text":"<p>The first step for using Sensitive Data Protection is to onboard AWS accounts. To do so, you need to deploy an \"Agent CloudFormation Stack\" in the AWS account.</p> <p>For the permissions required by the agent stack, refer to Appendix: Permissions for agent Cloudformation stack.</p>"},{"location":"user-guide/data-source/#add-aws-accounts-individually","title":"Add AWS accounts (individually)","text":"<ol> <li>Sign in to the solution's web portal.</li> <li>Choose Connect to data source in the Summary area. Alternatively, choose Connect to data source from the left navigation pane. </li> <li>Choose Add new account(s) to open the Individual account tab.</li> <li>Follow the instructions in Step1 and Step2 to install the Agent CloudFormation Stack.</li> <li>After successfully deploying the stack, fill in the account ID of the AWS account.</li> <li>Choose Add this account.</li> <li>Go back to the Connect to data source page. You will see that the AWS account has been added. </li> </ol> <p>You can also click one specific AWS account ID to check account details.</p>"},{"location":"user-guide/data-source/#add-aws-accounts-via-organization","title":"Add AWS accounts (via Organization)","text":"<p>For multiple AWS accounts, you can use AWS Organization to automatically install and uninstall the agent CloudFormation stacks. For more details, refer to Appendix: Add AWS accounts via Organization.</p> <p>After successfully deploying the stack, fill in the account ID of the Organization delegator account.</p> <p>Go back to the Connect to data source page, and you will see a list of AWS accounts added. You can click one specific AWS account ID to check account details.</p>"},{"location":"user-guide/discovery-job-create/","title":"Create job","text":"<p>You can create and manage jobs for detecting sensitive data. A discovery job consists of one or many AWS Glue jobs for actual data detection. For more information, refer to View job details.</p>"},{"location":"user-guide/discovery-job-create/#create-a-discovery-job","title":"Create a discovery job","text":"<ol> <li>Sign in to the solution's web portal.</li> <li>Choose Run sensitive data discovery jobs in the Summary area. Alternatively, from the left navigation pane, choose Run sensitive data discovery jobs to open its page. </li> <li> <p>Choose Create sensitive data discovery job. You'll need to go through the following steps to create a new discovery job.</p> <ul> <li>Step 1: Select the S3 data source</li> <li>Step 2: Select the RDS data source</li> <li>Step 3: Job settings (see the section Job setting details)</li> <li>Step 4: Job preview</li> </ul> </li> <li> <p>After previewing the job, choose Run job.</p> </li> </ol>"},{"location":"user-guide/discovery-job-create/#job-setting-details","title":"Job setting details","text":"Job setting Description Options Scan frequency Refers to the scan frequency of the discovery job. On-demand run Daily Weekly Monthly Scan depth Refers to the number of sampled rows. 1000(recommended) 100 Scan range Defines the overall scan range for the target data source.  \"Full scan\" means to scan all target data sources.\"Incremental scan\" means to skip those data sources that were not changed since the last data catalog update. Full scan Incremental scan (recommended) Detection threshold Defines the level of tolerance required for the job. If the scan depth is 1000 rows, a 10% threshold means that if over 100 rows (out of 1000) match the identifier rule, then the column will be labeled as sensitive. A lower threshold indicates that the job is less tolerant of sensitive data. 10% (recommended) 20% 30% 40% 50% 100% Override privacy labels that are updated manually Choose whether to allow the job to override the data catalog privacy label with the job result. Do not override (recommended) Override"},{"location":"user-guide/discovery-job-details/","title":"View job details","text":"<p>A sensitive data discovery job consists of Glue jobs that run in monitored AWS accounts (the same account as the data source). </p> <p>For instance, if you run a discovery job for a RDS instance (the data source) in Account A, and the solution is installed in Account B, the Glue job runs in Account A and returns results and masked sample data to Account B.</p>"},{"location":"user-guide/discovery-job-details/#view-job-details","title":"View job details","text":"<ol> <li>Sign in to the solution's web portal.</li> <li>Choose Run sensitive data discovery jobs in the Summary area. Alternatively, from the left navigation pane, choose Run sensitive data discovery jobs to open its page. </li> <li>Click the job that you want to view details. A window pops up. </li> <li>In the Job history tab, choose a specific job. If needed, you can choose Download report to download a report. For details, refer to discovery job report.</li> <li> <p>Click Job run details. You will be redirected to job details page, where you can see the job information and a list of Glue jobs. </p> <p>Note</p> <p>In case a Glue job failed, you can click the FAILED status to view its error log.</p> </li> </ol>"},{"location":"user-guide/discovery-job-details/#download-snapshot-of-classification-template-used-in-job","title":"Download snapshot of classification template used in job","text":"<p>You can download the template snapshot for the moment when the job starts to run. The snapshot shows what the job is using as data identifiers. </p> <p>On the job details page, choose Download snapshot to download the template snapshot in JSON format(.json). </p>"},{"location":"user-guide/discovery-job-pause-and-cancel/","title":"Pause/Continue job","text":"<p>You can only pause or resume a scheduled job. It does NOT mean to pause or resume a running discovery job.</p> <p>To pause a scheduled job, on the Run Sensitive Data Discovery Jobs page, click Actions and select Pause. For instance, if you scheduled a monthly job on the first day of every month and ran a job once in January, choosing Pause will prevent the discovery job from being executed in February.</p> <p>To resume a paused job, on the Run Sensitive Data Discovery Jobs page,click Actions and select Continue.</p>"},{"location":"user-guide/discovery-job-report/","title":"Download job report","text":"<p>On the Run sensitive data discovery job page, click into a specific job to open a window. In the Job history tab, choose a specific job, and choose Download report to download report in Excel format (.xlsx). </p> <p>In the report, each data source is in a separate sheet (tab). For example, a sensitive data discovery job runs for S3 and RDS:</p> <p>The S3 sheet is:</p> account_id region s3_bucket s3_location column_name identifiers sample_data 177416885226 cn-northwest-1 sdps-beta-member s3://sdps-beta-member/ col1 [{identifier=CHINESE-NAME, score=0.6680557137733704}] [cn_*, \u9b4f, \u6881, , , , \u5c39, \u6c49, , \u9c81*] 177416885226 cn-northwest-1 sdps-beta-member s3://sdps-beta-member/ col2 [{identifier=ADDRESS, score=0.6929563446207209}] [cn_*, , \u6d77\u5357\u7701\u7701\u76f4\u8f96\u53bf**, \u6e56\u5317\u7701\u6b66\u6c49\u5e02**, , \u8d35\u5dde\u7701\u516d\u76d8*, \u6e56\u5317\u7701\u968f\u5dde\u5e02**, \u4e0a\u6d77\u5e02\u5e02\u8f96\u533a\u5609**, \u5c71\u897f\u7701\u5ffb\u5dde*, \u8d35\u5dde\u7701\u94dc\u4ec1\u5e02****] <p>The RDS sheet is:</p> account_id region rds_instance_id table_name column_name identifiers sample_data 640463273335 cn-northwest-1 db-instance-2 orderpaymentdb_orderpaymenttable cn_bank_card [{identifier=BANK-CARD-NUMBER, score=0.5269872423945045}] [62426**, 62061*, 627582**, 625612*, 624299**, 3462**, 627119*, 426927*, 620930**, 62385**] 640463273335 cn-northwest-1 db-instance-1-instance-1 shipmenttrackingdb_shipmenttable cn_car_license [{identifier=ADDRESS, score=0.10789832248611221}, {identifier=NUMBER-PLATE, score=1.0}] [\u6d25JE*, \u743cWM, \u8c6bRU, \u85cfGK, \u9ed1YR, \u6caaVK, \u4eacR7, \u664bD3, \u82cfT *, \u6e1dC1*]"},{"location":"user-guide/discovery-job-rerun-and-duplicate/","title":"Re-run/Duplicate job","text":""},{"location":"user-guide/discovery-job-rerun-and-duplicate/#re-run-a-discovery-job","title":"Re-run a discovery Job","text":"<p>On the Run Sensitive Data Discovery Jobs page, click Actions and select Execute once. You can create a new discovery job and run it with the same settings as the previous run.</p>"},{"location":"user-guide/discovery-job-rerun-and-duplicate/#duplicate-a-discovery-job","title":"Duplicate a Discovery Job","text":"<p>On the Run Sensitive Data Discovery Jobs page, click Actions and select Duplicate. You can duplicate a job setting and modify it to start a new job.</p>"},{"location":"user-guide/get-started/","title":"Overview","text":"<p>Once successfully deployed the solution, you can access the web portal to detect sensitive data. </p>"},{"location":"user-guide/get-started/#steps","title":"Steps","text":"<ul> <li>Step 1: Connect to data source. Add AWS accounts and create data catalogs.</li> <li>Step 2: Browse data catalogs With data catalog, you can see the metadata (e.g, table schema) of data source.</li> <li>Step 3: Define classification template. Define sensitive data in templates by managing data identifiers.</li> <li>Step 4: Create and run sensitive data discovery jobs. Detect sensitive data by creating and managing data discovery jobs.</li> <li>Step 5: Check dashboard in Summary page and the updated data catalogs</li> </ul>"},{"location":"user-guide/sensitive-data-discovery-job/","title":"Sensitive Data Discovery Job","text":"<p>On the \"Run Sensitive Data Discovery Jobs\" webpage, you can create and manage jobs for discovering sensitive data. A discovery job consists of one or many AWS Glue jobs for actual data inspection.</p> <p>Note: The Glue jobs run in the same account as the data source. For instance, if you run a discovery job against an RDS instance (the data source) in Account A, and the solution is installed in Account B, the Glue job runs in Account A and returns results and masked sample data to Account B.</p>"},{"location":"user-guide/sensitive-data-discovery-job/#create-a-discovery-job","title":"Create a discovery Job","text":"<p>Click the \"Create sensitive data discovery job\" button. You'll need to go through the job settings to run a new discovery job.</p> <ul> <li>Step 1: Select the S3 data source<ul> <li>All buckets in all AWS accounts</li> <li>All buckets in specific AWS accounts</li> <li>All buckets with created catalogs</li> <li>Specific buckets with created catalogs</li> <li>Skip scanning for S3</li> </ul> </li> <li>Step 2: Select the RDS data source<ul> <li>All RDS instances with created catalogs</li> <li>Specific instances with created catalogs</li> <li>Skip scanning for RDS</li> </ul> </li> <li>Step 3: Job settings</li> <li>Step 4: Job preview</li> </ul> <p>After previewing the job, click \"Run job\" button to start.</p>"},{"location":"user-guide/sensitive-data-discovery-job/#re-run-a-discovery-job","title":"Re-run a discovery Job","text":"<p>Click \"Actions\" and select \"Execute once\". You can create a new discovery job and run it with the same settings as the previous run.</p>"},{"location":"user-guide/sensitive-data-discovery-job/#pausecontinue-a-discovery-job","title":"Pause/Continue a discovery Job","text":"<p>\"Pause\"/\"Continue\" can only be applied to a scheduled job. It does NOT mean to stop/resume a running discovery job.</p> <p>To pause a scheduled job, click \"Actions\" and select \"Pause\". For instance, if you scheduled a monthly job on the first day of every month and ran a job once in January, choosing \"Pause\" will prevent the discovery job from executing in February.</p> <p>To resume a paused job, click \"Actions\" and select \"Continue\"**.</p>"},{"location":"user-guide/sensitive-data-discovery-job/#duplicate-a-discovery-job","title":"Duplicate a Discovery Job","text":"<p>Click \"Actions\" and select \"Duplicate\". You can duplicate a job setting and modify it to start a new job.</p>"},{"location":"user-guide/sensitive-data-discovery-job/#view-job-details","title":"View job details","text":""}]}